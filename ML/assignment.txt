Divided into sets :
['a','m','n','s','t','o','x'],
['b','e','c'],
['h','k','u','v'],
['g','q'],
['d','r','p'],
['f'],
['l'],
['i'],
['w'],
['y']
Features :
pinchStrength,grabStrength,thumb_meta_proxi,thumb_proxi_inter,index_meta_proxi,
index_proxi_inter,middle_meta_proxi,middle_proxi_inter,ring_meta_proxi,
ring_proxi_inter,pinky_meta_proxi,pinky_proxi_inter,thumb_index,index_middle,
middle_ring,ring_pinky,palm_direction,thumb_direction_x,thumb_direction_y,
thumb_direction_z,index_direction_x,index_direction_y,index_direction_z,
middle_direction_x,middle_direction_y,middle_direction_z,ring_direction_x,
ring_direction_y,ring_direction_z,pinky_direction_x,pinky_direction_y,
pinky_direction_z,label
--------------------------------------------------------------------------------------

Randomly 1 letter was taken from each set and a model trained with them then tested
with test data
Done 100 times and taken average
Data was normalized by using preprocessing.standardScalar()

['a', 'm', 'n', 's', 't', 'q', 'o', 'g', 'x']
SVM : 0.877405063291
[[3470    0    7   11    4    1    0    7    0]
 [  28 3312   32    6   10   33   34   35   10]
 [  44    6 2540  568   24   12  233   73    0]
 [  31    0  578 2513    3    0  249  126    0]
 [  13   14   56   44 3282   50    6    6   29]
 [  38  117    2    1   57 3205   31   25   24]
 [ 169   10  203  239   15    8 2920   36    0]
 [  16   42   77  197   15   15   91 3047    0]
 [   0   29    0    1   25    6    0    2 3437]]
KNN : 0.850949367089
[[3432    0    6    0   19    1    2   40    0]
 [  70 2933   63  114   98  101    9   70   42]
 [  69    0 2892  208   27    0  127  177    0]
 [  31   27  346 2594   20   29  198  255    0]
 [  58   29   72  151 3005    0   88   90    7]
 [  26  163   14    8   88 3062   38   74   27]
 [ 171    5  251  247    1   41 2724  160    0]
 [ 107   50  168  250   20   41   56 2808    0]
 [   0    0    0   35   25    0    0    0 3440]]
DTREE : 0.863702531646
[[3322    0   35   26   28    5   34   50    0]
 [   0 3398    4    9   10   30   14   13   22]
 [  74    5 2429  472   33    5  289  192    1]
 [  29    8  446 2537   11    7  196  266    0]
 [  36    5   68   24 3277    1   17   28   44]
 [   6   50   11   15    4 3358   33    3   20]
 [  48   41  296  221    8   33 2803  148    2]
 [  51    3  200  284   23    1  148 2780   10]
 [   0   10    1    2   52   21    6   19 3389]]
SGD : 0.473797468354
[[2126   38  267  479   45   52  126  367    0]
 [  69 2118  125   80  143  614   98  218   35]
 [ 225  198  832  809  351   68  642  375    0]
 [ 348  126  737  899  207   40  620  523    0]
 [  99  149  286  308 1639   83  356  205  375]
 [  40  839  125   44   51 1857  134  329   81]
 [ 228  140  609  622  283  112 1279  327    0]
 [ 328  284  378  599  172  280  379 1074    6]
 [   8  145    5   13   73   61   12   35 3148]]
LDA : 0.846107594937
[[3469    0    0   27    0    0    0    4    0]
 [   1 3339   46   22   10   22   17   43    0]
 [  40    0 2410  601    0    0  306  143    0]
 [  21    0  384 2176    0    0  462  457    0]
 [ 108    0   58    3 3275    0   22   16   18]
 [  57   31    0    0   21 3272  118    0    1]
 [  97    0  283  402   16    0 2656  146    0]
 [  26    0  177  455    0    0   98 2744    0]
 [   0    0    0    0   77    0    0   27 3396]]

['b', 'e', 'c']
SVM : 0.99045045045
[[3483   17    0]
 [  16 3460   24]
 [  27   22 4051]]
KNN : 0.981081081081
[[3485   15    0]
 [  17 3372  111]
 [  46   21 4033]]
DTREE : 0.992252252252
[[3472    9   19]
 [   9 3474   17]
 [  31    1 4068]]
SGD : 0.965045045045
[[3446   25   29]
 [   3 3338  159]
 [  55  117 3928]]
LDA : 0.995315315315
[[3500    0    0]
 [   0 3500    0]
 [  52    0 4048]]
['h', 'k', 'u', 'v']
SVM : 0.982285714286
[[3437   59    4    0]
 [  11 3411    0   78]
 [  26    0 3474    0]
 [   1   69    0 3430]]
KNN : 0.960357142857
[[3344   69   87    0]
 [   4 3266   39  191]
 [ 113    2 3353   32]
 [   0   18    0 3482]]
DTREE : 0.976714285714
[[3425   53    7   15]
 [  38 3364   16   82]
 [   9    1 3490    0]
 [   0  105    0 3395]]
SGD : 0.770642857143
[[2833  172  488    7]
 [ 228 2556   33  683]
 [ 600   48 2743  109]
 [  24  767   52 2657]]
LDA : 0.985928571429
[[3474   14    3    9]
 [  55 3426    0   19]
 [  24    0 3476    0]
 [   0   71    2 3427]]
['d', 'r', 'p']
SVM : 0.981909090909
[[3927   13   60]
 [  26 3455   19]
 [  58   23 3419]]
KNN : 0.978909090909
[[3905   16   79]
 [  19 3481    0]
 [ 118    0 3382]]
DTREE : 0.975
[[3887    9  104]
 [   4 3490    6]
 [ 122   30 3348]]
SGD : 0.923818181818
[[3630  189  181]
 [ 241 3192   67]
 [ 109   51 3340]]
LDA : 0.983
[[3906    4   90]
 [   0 3498    2]
 [  64   27 3409]]

------------------------------------------------------------------------------------
When set is trained as whole
ie : Model that only classifies which set a letter belongs to
SVM Accuracy : 98.9%
Dtree Accuracy : 97.9%
KNN Accuracy : 98.6%
LDA Accuracy : 95.0%
SGD Accuracy : 83.2%
-------------------------------------------------------------------------------------
